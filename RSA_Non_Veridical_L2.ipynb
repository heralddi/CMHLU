{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import add\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSAModel():\n",
    "    def __init__(self, objects, messages, truth_table, alpha, prior_o, cost_function):\n",
    "        if np.shape(truth_table) != (len(messages), len(objects)):\n",
    "            raise ValueError(\"\"\"Truth matrix must be m x n, \n",
    "            where m is number of messages and n is the number of objects\"\"\")\n",
    "        self.objects = objects\n",
    "        self.messages = messages\n",
    "        self.truth_table = truth_table # Literal meaning L(m,o)\n",
    "        self.alpha = alpha\n",
    "        self.prior_o = np.array(prior_o)\n",
    "        self.cost_function = cost_function\n",
    "        \n",
    "        self.n_obj = len(self.objects)\n",
    "        self.n_mes = len(self.messages)\n",
    "    \n",
    "    def normalize(self, arr, axis=1):\n",
    "        epsilon = 1e-10 # To prevent division by zero\n",
    "        if axis == 1: # Normalize rows\n",
    "            row_sums = arr.sum(axis=1)[:, np.newaxis]\n",
    "            return arr / (row_sums + epsilon)\n",
    "        elif axis == 0: # Normalize columns\n",
    "            col_sums = arr.sum(axis=0)[np.newaxis, :]\n",
    "            return arr / (col_sums + epsilon)\n",
    "        else:\n",
    "            raise ValueError(\"Axis must be 0 or 1 for normalization.\")\n",
    "\n",
    "    # Literal Listener L0: P_L0(o|m) ∝ P(o) * Lit(m,o)\n",
    "    # Lit(m,o) is 1 if message m is true of object o, 0 otherwise (from truth_table)\n",
    "    def L0(self):\n",
    "        # P(o) repeated for each message\n",
    "        prior_o_repeated = np.tile(self.prior_o, (self.n_mes, 1)) # Shape (n_mes, n_obj)\n",
    "        # P(o) * Lit(m,o)\n",
    "        unnorm_L0 = self.truth_table * prior_o_repeated # Element-wise. Shape (n_mes, n_obj)\n",
    "        # Normalize over objects o for each message m (normalize rows)\n",
    "        norm_L0_o_given_m = self.normalize(unnorm_L0, axis=1)\n",
    "        return norm_L0_o_given_m # P_L0(o|m)\n",
    "\n",
    "    # Pragmatic Speaker S1: P_S1(m|o) ∝ exp(alpha * (log P_L0(o|m) - C(m)))\n",
    "    # Utility U(m;o) = log P_L0(o|m) - C(m)\n",
    "    def S1(self):\n",
    "        epsilon = 1e-10\n",
    "        \n",
    "        # Get P_L0(o|m) from L0()\n",
    "        L0_o_given_m = self.L0() # Shape (n_mes, n_obj)\n",
    "        \n",
    "        # Calculate log P_L0(o|m)\n",
    "        log_L0_o_given_m = np.log(L0_o_given_m + epsilon) # Shape (n_mes, n_obj)\n",
    "        \n",
    "        # Costs C(m)\n",
    "        message_costs = np.array(self.cost_function())[:, np.newaxis] # Shape (n_mes, 1)\n",
    "        \n",
    "        # Utility U(m;o) = log P_L0(o|m) - C(m)\n",
    "        utility = log_L0_o_given_m - message_costs # Broadcasting. Shape (n_mes, n_obj)\n",
    "        \n",
    "        # S1(m|o) ∝ exp(alpha * U(m;o))\n",
    "        # This should be normalized over messages m for each object o.\n",
    "        # So we need exp(alpha * utility.T) and then normalize its rows.\n",
    "        unnorm_S1_m_given_o_T = np.exp(self.alpha * utility.T) # Shape (n_obj, n_mes)\n",
    "        norm_S1_m_given_o = self.normalize(unnorm_S1_m_given_o_T, axis=1)\n",
    "        \n",
    "        return norm_S1_m_given_o # P_S1(m|o)\n",
    "\n",
    "    # Pragmatic Listener L1: P_L1(o|m) ∝ P_S1(m|o) * P(o)\n",
    "    def L1(self):\n",
    "        # P_S1(m|o) from S1()\n",
    "        S1_m_given_o = self.S1() # Shape (n_obj, n_mes)\n",
    "        \n",
    "        # P(o)\n",
    "        # prior_o_array = self.prior_o # Shape (n_obj,)\n",
    "        \n",
    "        # P_L1(o|m) ∝ P_S1(m|o)P(o)\n",
    "        # We want the result to be (n_mes, n_obj), normalized over objects o for each message m.\n",
    "        # P_S1(m|o) * P(o) term: S1_m_given_o * self.prior_o[:, np.newaxis]\n",
    "        # This gives a matrix of shape (n_obj, n_mes) where element (o,m) is P_S1(m|o)P(o).\n",
    "        # To get P_L1(o|m), we need to consider this as P_S1(m|o)P(o) for each (m,o) pair,\n",
    "        # and then for a given m, normalize over o.\n",
    "        # So, we are looking for (P_S1(m|o)P(o))^T, then normalize rows.\n",
    "        \n",
    "        numerator_L1 = (S1_m_given_o * self.prior_o[:, np.newaxis]).T # Shape (n_mes, n_obj)\n",
    "                                                                     # Row i is P(m_i|o_j)P(o_j) for all j\n",
    "        norm_L1_o_given_m = self.normalize(numerator_L1, axis=1) # Normalize rows\n",
    "        \n",
    "        return norm_L1_o_given_m # P_L1(o|m)\n",
    "\n",
    "    def plot(self, filename=None, title_suffix=''):\n",
    "        if filename is not None and not isinstance(filename, str):\n",
    "            raise TypeError(\"If a filename is provided, it must be a string\")\n",
    "        \n",
    "        L1_probs = self.L1() # P_L1(o|m), shape (n_mes, n_obj)\n",
    "        \n",
    "        # Determine number of subplots needed\n",
    "        num_messages = self.n_mes\n",
    "        \n",
    "        fig, axes = plt.subplots(num_messages, 1, figsize=(8, num_messages * 3.5), squeeze=False) \n",
    "        # squeeze=False ensures axes is always 2D\n",
    "        \n",
    "        for i, message in enumerate(self.messages):\n",
    "            ax = axes[i, 0] # Access subplot\n",
    "            ax.bar(self.objects, L1_probs[i, :])\n",
    "            ax.set_title(f'L1 P(object | message \"{message}\") {title_suffix}')\n",
    "            ax.set_xlabel('Objects/States')\n",
    "            ax.set_ylabel('Probability')\n",
    "            ax.set_ylim([0, 1])\n",
    "            ax.tick_params(axis='x', rotation=45) # Rotate x-axis labels for better readability\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if filename:\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSAExtended(RSAModel):\n",
    "    def __init__(self, objects, messages, truth_table, alpha, prior_o, prior_m, cost_function):\n",
    "        super().__init__(objects, messages, truth_table, alpha, prior_o, cost_function)\n",
    "        self._raw_prior_m = np.array(prior_m) # Store raw before normalization for setter\n",
    "        self.prior_m = prior_m # This is P(m), will be normalized by setter\n",
    "\n",
    "    # Overrides S1 to include P(m)\n",
    "    # Pragmatic Speaker S1: P_S1(m|o) ∝ exp(alpha * (log P_L0(o|m) - C(m))) * P(m)\n",
    "    def S1(self):\n",
    "        epsilon = 1e-10\n",
    "        \n",
    "        # Get P_L0(o|m) from L0()\n",
    "        L0_o_given_m = self.L0() # Shape (n_mes, n_obj)\n",
    "        \n",
    "        # Calculate log P_L0(o|m)\n",
    "        log_L0_o_given_m = np.log(L0_o_given_m + epsilon) # Shape (n_mes, n_obj)\n",
    "        \n",
    "        # Costs C(m)\n",
    "        message_costs = np.array(self.cost_function())[:, np.newaxis] # Shape (n_mes, 1)\n",
    "        \n",
    "        # Utility U(m;o) = log P_L0(o|m) - C(m)\n",
    "        utility_with_cost = log_L0_o_given_m - message_costs # Broadcasting. Shape (n_mes, n_obj)\n",
    "        \n",
    "        # S1(m|o) ∝ exp(alpha * U(m;o)) * P(m)\n",
    "        # We need exp(alpha * utility.T) which is (n_obj, n_mes)\n",
    "        # Then multiply by P(m) (shape (n_mes,)) and normalize rows.\n",
    "        exp_alpha_utility_T = np.exp(self.alpha * utility_with_cost.T) # Shape (n_obj, n_mes)\n",
    "        \n",
    "        # Multiply by P(m). self._prior_m is (n_mes,) normalized.\n",
    "        # Each row of exp_alpha_utility_T corresponds to an object o.\n",
    "        # For each o, P(m|o) is scaled by P(m).\n",
    "        unnorm_S1_m_given_o_T = exp_alpha_utility_T * self._prior_m # Broadcasting P(m) across rows. Shape (n_obj, n_mes)\n",
    "\n",
    "        norm_S1_m_given_o = self.normalize(unnorm_S1_m_given_o_T, axis=1) # Normalize rows\n",
    "        \n",
    "        return norm_S1_m_given_o # P_S1(m|o)\n",
    "    \n",
    "    @property\n",
    "    def prior_m(self):\n",
    "        return self._prior_m\n",
    "    \n",
    "    @prior_m.setter\n",
    "    def prior_m(self, prior_m_values):\n",
    "        if len(prior_m_values) == self.n_mes:\n",
    "            # Store raw values for potential future use if needed\n",
    "            self._raw_prior_m = np.array(prior_m_values)\n",
    "            # Normalize and store the normalized prior\n",
    "            sum_priors = np.sum(prior_m_values)\n",
    "            if sum_priors == 0: # Avoid division by zero if all priors are zero\n",
    "                self._prior_m = np.ones(self.n_mes) / self.n_mes # Uniform if sum is zero\n",
    "            else:\n",
    "                self._prior_m = np.array(prior_m_values) / sum_priors\n",
    "        else:\n",
    "            raise ValueError('Length of prior_m must equal the number of messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Interpreting \"hope-wh\" Utterances\n",
    "\n",
    "This section models a scenario where a speaker expresses a preference about an uncertain situation 'S'.\n",
    "- **Objects/States (o):** The speaker's internal state of desire.\n",
    "  - `o1 (desire_positive_S)`: Speaker desires a positive outcome for S.\n",
    "  - `o2 (uncertain_about_S)`: Speaker is uncertain/information-seeking about S.\n",
    "- **Messages (m):**\n",
    "  - `m1 (\"hope that S_good\")`: \"I hope that S turns out good.\" (Standard, explicitly positive preference)\n",
    "  - `m2 (\"wonder what S\")`: \"I wonder what S will be.\" (Standard, information-seeking)\n",
    "  - `m3 (\"hope what S\")`: \"I hope what S will be.\" (Target marked/L2 utterance)\n",
    "\n",
    "The listener (L1) infers the speaker's state (o) given their utterance (m)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_s = ['desire_positive_S', 'uncertain_about_S']\n",
    "messages_s = ['hope_that_S_good', 'wonder_what_S', 'hope_what_S']\n",
    "\n",
    "# truth_table[message_idx, object_idx] = 1 if message is compatible with object/state, else 0\n",
    "# m1 (\"hope that S_good\") is compatible with o1 (desire_positive_S)\n",
    "# m2 (\"wonder what S\") is compatible with o2 (uncertain_about_S)\n",
    "# m3 (\"hope what S\") is assumed, if uttered, to express a desire for a positive outcome, so compatible with o1.\n",
    "truth_table_s = np.array([\n",
    "    [1, 0],  # m1 compatible with o1\n",
    "    [0, 1],  # m2 compatible with o2\n",
    "    [1, 0]   # m3 compatible with o1 (semantic/pragmatic assumption about its intended use)\n",
    "])\n",
    "\n",
    "# P(o): Prior probability for the speaker's underlying state\n",
    "prior_o_s = np.array([0.5, 0.5]) \n",
    "alpha_s = 3.0 # Speaker optimality parameter (higher means more \"rational\" choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Native Speaker Model\n",
    "\n",
    "Assumptions for the native speaker model:\n",
    "- The marked utterance `m3 (\"hope what S\")` has a higher cost (reflecting lower grammaticality or preference for native speakers).\n",
    "- The prior probability of a native speaker uttering `m3` is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_native_s():\n",
    "    # Costs for [\"hope_that_S_good\", \"wonder_what_S\", \"hope_what_S\"]\n",
    "    return np.array([0, 0, 2.0]) # m3 has a higher cost\n",
    "\n",
    "# P(m): Prior over messages for native speaker\n",
    "# Low prior for the marked utterance m3\n",
    "prior_m_native_s = np.array([0.49, 0.49, 0.02])\n",
    "\n",
    "RSA_native_s_model = RSAExtended(\n",
    "    objects_s, \n",
    "    messages_s, \n",
    "    truth_table_s, \n",
    "    alpha_s, \n",
    "    prior_o_s, \n",
    "    prior_m_native_s, \n",
    "    cost_function_native_s\n",
    ")\n",
    "\n",
    "print(\"--- Native Speaker Model ---\")\n",
    "print(\"L0(object | message):\")\n",
    "print(f\"{objects_s}\")\n",
    "L0_native = RSA_native_s_model.L0()\n",
    "for i, msg in enumerate(messages_s):\n",
    "    print(f\"{msg}: {L0_native[i,:]}\")\n",
    "\n",
    "print(\"\\nS1(message | object):\")\n",
    "print(f\"          {messages_s}\")\n",
    "S1_native = RSA_native_s_model.S1()\n",
    "for i, obj in enumerate(objects_s):\n",
    "    print(f\"{obj}: {S1_native[i,:]}\")\n",
    "    \n",
    "print(\"\\nL1(object | message):\")\n",
    "print(f\"          {objects_s}\")\n",
    "L1_native_s = RSA_native_s_model.L1()\n",
    "for i, msg in enumerate(messages_s):\n",
    "    print(f\"{msg}: {L1_native_s[i,:]}\")\n",
    "\n",
    "RSA_native_s_model.plot(filename='RSA_hope_wh_native.png', title_suffix='(Native Model)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Native Speaker Model (Listener modeling an L2 Speaker)\n",
    "\n",
    "Assumptions for the non-native speaker model (or a listener modeling an L2 speaker):\n",
    "- The marked utterance `m3 (\"hope what S\")` may have a lower perceived cost or penalty compared to the native model.\n",
    "- The prior probability of the L2 speaker uttering `m3` might be higher than for a native speaker (e.g., due to L1 transfer, overgeneralization of L2 rules, or less sensitivity to markedness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_nonnative_s():\n",
    "    # Costs for [\"hope_that_S_good\", \"wonder_what_S\", \"hope_what_S\"]\n",
    "    return np.array([0, 0, 0.5]) # m3 has a lower cost for L2 speaker model\n",
    "\n",
    "# P(m): Prior over messages for non-native speaker model\n",
    "# Higher prior for the marked utterance m3 compared to native model\n",
    "prior_m_nonnative_s = np.array([0.4, 0.4, 0.2])\n",
    "\n",
    "RSA_nonnative_s_model = RSAExtended(\n",
    "    objects_s, \n",
    "    messages_s, \n",
    "    truth_table_s, \n",
    "    alpha_s, \n",
    "    prior_o_s, \n",
    "    prior_m_nonnative_s, \n",
    "    cost_function_nonnative_s\n",
    ")\n",
    "\n",
    "print(\"--- Non-Native Speaker Model ---\")\n",
    "print(\"L0(object | message):\")\n",
    "print(f\"{objects_s}\")\n",
    "L0_nonnative = RSA_nonnative_s_model.L0()\n",
    "for i, msg in enumerate(messages_s):\n",
    "    print(f\"{msg}: {L0_nonnative[i,:]}\")\n",
    "\n",
    "print(\"\\nS1(message | object):\")\n",
    "print(f\"          {messages_s}\")\n",
    "S1_nonnative = RSA_nonnative_s_model.S1()\n",
    "for i, obj in enumerate(objects_s):\n",
    "    print(f\"{obj}: {S1_nonnative[i,:]}\")\n",
    "\n",
    "print(\"\\nL1(object | message):\")\n",
    "print(f\"          {objects_s}\")\n",
    "L1_nonnative_s = RSA_nonnative_s_model.L1()\n",
    "for i, msg in enumerate(messages_s):\n",
    "    print(f\"{msg}: {L1_nonnative_s[i,:]}\")\n",
    "\n",
    "RSA_nonnative_s_model.plot(filename='RSA_hope_wh_nonnative.png', title_suffix='(Non-Native Model)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discussion of Results\n",
    "\n",
    "By comparing the `L1(object | message)` probabilities, particularly for `m3 (\"hope what S\")`, between the native and non-native speaker models, we can observe how the listener's interpretation shifts based on their model of the speaker.\n",
    "\n",
    "Specifically, we are interested in `L1('desire_positive_S' | \"hope what S\")`.\n",
    "- In the **Native Model**, this probability might be low if the high cost and low prior of `m3` make it an unlikely choice, even if the speaker desires a positive outcome. The listener might be confused or assign low probability to any specific state given such a marked utterance.\n",
    "- In the **Non-Native Model**, if `m3` is less costly and has a higher prior, the listener might be more willing to infer `o1 ('desire_positive_S')` from it. This would happen if `m3`, despite being marked, becomes a more viable signal for conveying this state under the listener's assumptions about an L2 speaker's linguistic system.\n",
    "\n",
    "The plots visualize these L1 listener probabilities. If `L1('desire_positive_S' | \"hope what S\")` is higher in the Non-Native Model than in the Native Model, it would suggest that modeling the speaker as non-native makes the marked utterance a more informative signal of their desire for a positive outcome.\n",
    "\n",
    "**Note:**\n",
    "* The parameters used (costs, priors, alpha) are illustrative and would ideally be informed by empirical data or more detailed linguistic theory.\n",
    "* The specific implementation of the RSA model (especially the utility function U(m;o) and S1 definition) can vary. This notebook uses a common approach.\n",
    "* The definition of the `truth_table`, particularly for the marked utterance `m3`, inherently includes pragmatic assumptions about its intended meaning if used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}